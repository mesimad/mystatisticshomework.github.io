<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="UTF-8">
  <title>Statistics</title>
  <meta name="viewport" content="width=device-width, initial-scale=1"><link rel='stylesheet' href='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css'><link rel="stylesheet" href="./style.css">

</head>
<body>
<!-- partial:index.partial.html -->
<body>

    <div class="blog-masthead">
      <div class="container">
        <nav class="blog-nav">
          <a class="blog-nav-item active" href="index.html">Home</a>
          <a class="blog-nav-item" href="https://www.datatime.eu/public/cybersecurity/">About</a>
        </nav>
      </div>
    </div>

    <div class="container">
                <div class="blog-header">
                <h1 class="blog-title text-center">Statistics Homework</h1>
                <p class="lead blog-description"></p>
    </div>
    
                <div class="row">
                <div class="col-sm-8 blog-main">
                <div class="blog-post">
    
<h2 class="blog-post-title">Homework Seven</h2>
                <p class="blog-post-meta"> by <a href="https://www.linkedin.com/in/babasimaad/">Baba Simad</a></p>
                            
<h2>Research 9_R:</h2>
                <p><b>"History and derivation of the normal distribution. Touch, at least, the following three i mportant perspectives, putting them into an historical context to understand how  the idea developed: </p>
                <p>1) as approximation of binomial (De Moivre)
                <p>2) as error curve (Gauss)
                <p>3) as limit of sum of independent r.v.'s (Laplace)"</p></b>
                <br>
                <p>History and derivation of the normal distribution. Touch, at least, the following three important perspectives, putting them into an historical context to understand how the idea developed:
                <p>1) as approximation of binomial (De Moivre)
                <p>2) as error curve (Gauss)
                <p>3) as limit of sum of independent r.v.’s (Laplace)
                <p>Normal distribution:
                <p>In probability theory, a normal (or Gaussian or Gauss or Laplace–Gauss) distribution is a type of continuous probability distribution for a real-valued random variable. The general form of its probability density function is</p>
                <p><img src="img14.jpg" class="img-fluid" alt="Responsive image"></p>
                <p>De Moivre and the normal distribution as approximation of binomial</p>
                <p>Abraham de Moivre, an 18th century statistician and consultant to gamblers, was often called upon to make these lengthy computations. de Moivre noted that when the number of events (coin flips) increased, the shape of the binomial distribution approached a very smooth curve.</p>
                <p><img src="img15.jpg" class="img-fluid" alt="Responsive image"></p>
                <p>De Moivre reasoned that if he could find a mathematical expression for this curve, he would be able to solve problems such as finding the probability of 60 or more heads out of 100 coin flips much more easily. This is exactly what he did, and the curve he discovered is now called the “normal curve.”</p>
                <p><img src="img16.jpg" class="img-fluid" alt="Responsive image"></p>
                <br>
                <p>Errors following a normal distribution:</p>
                <p>The importance of the normal curve stems primarily from the fact that the distributions of many natural phenomena are at least approximately normally distributed. One of the first applications of the normal distribution was to the analysis of errors of measurement made in astronomical observations, errors that occurred because of imperfect instruments and imperfect observers. Galileo in the 17th century noted that these errors were symmetric and that small errors occurred more frequently than large errors. This led to several hypothesized distributions of errors, but it was not until the early 19th century that it was discovered that these errors followed a normal distribution. Independently, the mathematicians Adrain in 1808 and Gauss in 1809 developed the formula for the normal distribution and showed that errors were fit well by this distribution.</p>
                <br>
                <p>Central limit theorem and the sum of random variables:</p>
                <p>This same distribution had been discovered by Laplace in 1778 when he derived the extremely important central limit theorem. Laplace showed that even if a distribution is not normally distributed, the means of repeated samples from the distribution would be very nearly normally distributed, and that the larger the sample size, the closer the distribution of means would be to a normal distribution.</p>
                <p>Given a population with a finite mean μ and a finite non-zero variance σ2, the sampling distribution of the mean approaches a normal distribution with a mean of μ and a variance of σ2/N as N, the sample size, increases.</p>
                <br>

<h3>Bibliography:</h3>

          <p class="blog-post-meta"> [1] <a href="https://en.wikipedia.org/wiki/Normal_distribution">https://en.wikipedia.org/wiki/Normal_distribution/</a></p>
          <p class="blog-post-meta"> [2] <a href="https://onlinestatbook.com/2/normal_distribution/history_normal.html">https://onlinestatbook.com/2/normal_distribution/history_normal.html/</a></p>
          <p class="blog-post-meta"> [3] <a href="https://onlinestatbook.com/2/sampling_distributions/samp_dist_mean.html#clt">https://onlinestatbook.com/2/sampling_distributions/samp_dist_mean.html#clt/</a> </p>
          <br>
    
<h3>Application 9_A_1:</h3>

          <p><b>“Create a simulation with graphics to convince yourself of the uniform convergence of the empirical CDF to the theoretical distribution (Glivenko-Cantelli theorem). You may use a simple random variable of your choice for such a demonstration”</p></b>
          <p class="blog-post-meta"> Project: <a href="https://drive.google.com/drive/folders/1C59Yvworj15bWUhyIveW_dJ8F6cmPoJ4?usp=sharing">Click here.</a></p>
        <br>
        
        
        
<h3>Video:</h3>
            
                <br>
                <div class="embed-responsive embed-responsive-16by9">
                <iframe class="embed-responsive-item" src="HW9A.mp4" allowfullscreen></iframe>
                </div> 
                <br> 
                

<h3>Application 9_A_2:</h3>

            <p><b>“Generate sample paths of jump processes which at each time considered t = 1, …, n perform jumps computed as:
            <p>- σ R(t) (and/or divide by sqrt(1/t) in case you want to make constant the variance at each time by “normalizing” the sum, or divide by sqrt(1/n) in order to obtain standard deviation = σ at last time [the so called “scaling limit”])
            <p>where R(t) is a [-1,1] Rademacher random variable</p>
            <p>- σ Z(t), where Z(t) is a N(0,1) random variable”</p></b>
            <p class="blog-post-meta"> Project: <a href="https://drive.google.com/drive/folders/1oELnxkan1Nikv_wCpit5VtOjYiLNMVKd?usp=sharing">Click here.</a></p>
            <br>
            
<h3>Video:</h3>
                
                    <br>
                    <div class="embed-responsive embed-responsive-16by9">
                    <iframe class="embed-responsive-item" src="HW9AA.mp4" allowfullscreen></iframe>
                    </div> 
                    <br> 
<h3>Research 7_RA:</h2>

            <p><b>“Do a research about the random walk process and its properties. Compare your finding with your applications drawing your personal conclusions. Explain based on your exercise the beaviour of the distribution of the stochastic process (check out “Donsker’s invariance principle”). What are, in particular, its mean and variance at time n ?”</p></b>
            <br>
            <p>In mathematics, a random walk is a mathematical object, known as a stochastic or random process, that describes a path that consists of a succession of random steps on some mathematical space such as the integers.
            <p>In the simplest context the walk is in discrete time, that is a sequence of random variables (Xₜ) = (X₁, X₂, …) indexed by the natural numbers. However, it is also possible to define random walks which take their steps at random times, and in that case, the position X t has to be defined for all times t ∈ [0,+∞).
            <p>A natural way to think about the random walk is in term of paths. The outcome path s = (s1, s2, . . .) can be identified with the sequence (t, st), t = 0, 1, . . . of ordered pairs, or better yet with the graph of the piecewise linear function that connects the points (t, st) as shown in the next figure.</p>
            <p><img src="img17.jpg" class="img-fluid" alt="Responsive image"></p>
            <br>
           <p> We have the Donsker’s theorem (also known as Donsker’s invariance principle), it is a functional extension of the central limit theorem.
           <p>It says the following:
           <p>Let X₁,X₂,X₃,… be a sequence of independent and identically distributed random variables with mean 0. Let Sₙ be as follows:
           <img src="img18.jpg" class="img-fluid" alt="Responsive image">
           <p>We can define the stochastic process S = Sₙ where n ∈ N is known as a random walk. We define the diffusively rescaled random walk as
           <img src="img19.jpg" class="img-fluid" alt="Responsive image">
           <p>Donker’s invariance principle states that the random function W⁽ⁿ⁾ converges in distribution to a standard Brownian motion W as n -> ∞.
           <p>So it stands that, whatever is the distribution of Xᵢ, the distribution of the values acquired by W⁽ⁿ⁾ will be the same as the distribution of the values of a standard Brownian motion if n -> ∞.
           <p>This concept can be seen practically in the application 9_A_2.
           <p>When the simple walk is plotted we have that the distribution of the values is converging more and more to a distribution N(0,1) which is the same distribution of the values of the standard Brownian motion plotted in the second part of the video shown in the presentation of the application.
           <p>For the simple random walk, as already said before, for each instant t we have E Sₜ = 0 and Var Sₜ= t and they are equal to the variance and expected value of the standard Brownian motion.
           <br>
           <br>

<h3>Bibliography:</h3>

          <p class="blog-post-meta"> [1] <a href="https://en.wikipedia.org/wiki/Random_walk">https://en.wikipedia.org/wiki/Random_walk/</a></p>
          <p class="blog-post-meta"> [2] <a href="https://en.wikipedia.org/wiki/Donsker%27s_theorem">https://en.wikipedia.org/wiki/Donsker%27s_theorem/</a></p>
          <br>
           </div>

          <nav>
            <ul class="pager">
              <li><a href="next.html">Previous</a></li>
              
            </ul>
          </nav>
      
        </div><!-- /.blog-main -->
      
        <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
          <div class="sidebar-module sidebar-module-inset">
            <h4>About</h4>
            <p>"Prof. Tommaso Gastaldi"
            <p>"tommaso.gastaldi@gmail.com"</p>
            <p>Course: STATISTICS SECS-S/01 </p>
            <p>CFU: 6, Year: 2021-2022
            <p>Course Program: Topics in Statistics relevant to Cybersecurity: theory and application, with intensive software development (using Visual Studio, C# and/or VB.NET and/or J#). 
            <p>No previous programming experience needed, but useful.</p>
          </div>
          <div class="sidebar-module">
            <h4>Links</h4>
            <ol class="list-unstyled">
              <li><a href="HM1.html">Homework 1</a></li>
              <li><a href="HM2.html">Homework 2</a></li>
              <li><a href="HM3.html">Homework 3</a></li>
              <li><a href="HM4.html">Homework 4</a></li>
              <li><a href="HM5.html">Homework 5</a></li>
              <li><a href="HM6.html">Homework 6</a></li>
              <li><a href="HM7.html">Homework 7</a></li>
              <li><a href="HM8.html">Homework 8</a></li>
              <li><a href="HM9.html">Homework 9</a></li>
            </ol>
          </div>
          <div class="sidebar-module">
            <h4>Elsewhere</h4>
            <ol class="list-unstyled">
             
              <li><a href="https://www.facebook.com/me.simad/">Facebook</a></li>
              <li><a href="https://www.instagram.com/whosimad/">Instagram</a></li>
              <li><a href="https://www.linkedin.com/in/babasimaad/">Linkedin</a></li>
            </ol>
          </div>
        </div><!-- /.blog-sidebar -->
      
      </div><!-- /.row -->
      
      </div><!-- /.container -->
      
      <footer class="blog-footer">
      <p> Website Build by <a href="https://www.instagram.com/whosimad/">Baba Simad</a>.</p>
      <p>
        <a href="#">Back to top</a>
      </p>
      </footer>
      
      
      <!-- Bootstrap core JavaScript
      ================================================== -->
      <!-- Placed at the end of the document so the pages load faster -->
      <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
      <script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
      <script src="../../dist/js/bootstrap.min.js"></script>
      <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
      <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
      
      
      </body>
      <!-- partial -->
      <script src='https://code.jquery.com/jquery-2.2.4.min.js'></script>
      <script src='https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.11.4/jquery-ui.min.js'></script>
      <script src='https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js'></script>
      </body>
      </html>
      